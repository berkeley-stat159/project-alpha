% tex file for smoothing
\par \indent Due to the inherently random nature of human subjects and their 
movements, a certain level of smoothing must be performed on the spatial 
dataset. That way, the ‘noisy’ data can be cast off from the data that actually 
represents significant changes in blood flow in the brain. By doing so, 
researchers and anyone else investigating the data will be able to distinguish 
between non-brain scans versus actual brain scans. Each voxel of the brain is 
represented by a measure of blood flow intensity, and so a series of steps must 
be taken so that the data is correctly convolved to most closely and accurately 
depict what was happening at a certain point in the brain at a certain time. 
After researching quite extensively, we decided to use convolution involving a 
Gaussian kernel in order to smooth the three dimensional data. Originally, we 
were going to try and write a smoothing function from scratch, by implementing 
a rudimentary average-over-neighbors method. However, discussion with mentors 
lead us to the scipy module \texttt{ndimage.filters} that has a function to 
performs a Gaussian filter on n-dimensional data. This was exactly what we 
needed so rather than reinventing the wheel, we will be smoothing the data with 
this module.
